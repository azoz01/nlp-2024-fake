{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: does `model` returns `[0 prob, 1 prob]` before softmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    TextClassificationPipeline,\n",
    ")\n",
    "from engine.data import prepare_data_for_fine_tuning, read_data\n",
    "from engine.xai import FeatureAblationText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"roberta-base\"\n",
    "MODEL_PATH = \"output/checkpoint-2025/model.safetensors\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label\n",
      "0     Building a wall on the U.S.-Mexico border will...      0\n",
      "1     Wisconsin is on pace to double the number of l...      1\n",
      "2     Says John McCain has done nothing to help the ...      1\n",
      "4     When asked by a reporter whether hes at the ce...      1\n",
      "5     Over the past five years the federal governmen...      0\n",
      "...                                                 ...    ...\n",
      "1256  Says Chris Christies plan to kick-start our ec...      1\n",
      "1257  Obama used $20 million in federal money to emm...      1\n",
      "1260  I think its seven or eight of the California s...      1\n",
      "1261  Sen. Bob Menendez voted to enact a new tax on ...      1\n",
      "1266  Says the governor is going around the state ta...      1\n",
      "\n",
      "[790 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 790/790 [00:00<00:00, 4858.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test = read_data(\"data/split_raw/test.tsv\")\n",
    "print(test)\n",
    "test_dataset = prepare_data_for_fine_tuning(test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is available. Using GPU.\")\n",
    "        return \"cuda\"\n",
    "    else:\n",
    "        print(\"CUDA not available. Using CPU.\")\n",
    "        return \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_ID)\n",
    "device = get_device()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH, config=config\n",
    ")\n",
    "model.eval()\n",
    "pipeline = TextClassificationPipeline(\n",
    "    model=model, tokenizer=tokenizer, top_k=2, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if(device == \"cuda\"):\n",
    "    model.cuda()\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a wall on the U.S.-Mexico border will take literally years.\n",
      "tensor([[    0, 37500,    10,  2204,    15,     5,   121,     4,   104,  3358,\n",
      "         15780,  1424,    40,   185,  5909,   107,     4,     2]])\n"
     ]
    }
   ],
   "source": [
    "obs = test[\"text\"].tolist()[0]\n",
    "if(device == \"cuda\"):\n",
    "    obs_pt = pipeline.tokenizer(obs, return_tensors=\"pt\")['input_ids'].cuda()\n",
    "else:\n",
    "    obs_pt = pipeline.tokenizer(obs, return_tensors=\"pt\")['input_ids'].cpu()\n",
    "\n",
    "print(obs)\n",
    "print(obs_pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(obs):\n",
    "    return model(obs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<engine.xai.FeatureAblationText object at 0x0000021F19A16750>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  1.2517e-06,  3.8594e-06,  2.4736e-06,  6.5118e-06,\n",
       "           1.7881e-06,  4.5747e-06,  3.7402e-06,  8.7619e-06,  4.3064e-06,\n",
       "           1.2890e-05,  4.6194e-06,  4.6492e-06,  1.9222e-06,  4.7684e-07,\n",
       "           5.4240e-06,  4.8280e-06,  6.5118e-06],\n",
       "         [ 0.0000e+00,  5.9605e-08,  1.9260e-06,  1.1623e-06,  2.6114e-06,\n",
       "           9.5740e-07,  2.2333e-06,  1.8384e-06,  4.2710e-06,  2.2557e-06,\n",
       "           5.8804e-06,  1.8310e-06,  1.8794e-06,  7.7300e-07, -1.0617e-07,\n",
       "           2.6375e-06,  2.9430e-06,  3.6247e-06]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "attr = FeatureAblationText(forward)\n",
    "print(attr)\n",
    "exp = attr.get_attributions([obs_pt])\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Building', 'Ġa', 'Ġwall', 'Ġon', 'Ġthe', 'ĠU', '.', 'S', '.-', 'Mexico', 'Ġborder', 'Ġwill', 'Ġtake', 'Ġliterally', 'Ġyears', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "tokens = pipeline.tokenizer.convert_ids_to_tokens(obs_pt[0])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities in the text:\n",
      "U.S.-Mexico (ORG) - Companies, agencies, institutions, etc.\n",
      "literally years (DATE) - Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = NER(obs)\n",
    "\n",
    "print(\"Entities in the text:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} ({ent.label_}) - {spacy.explain(ent.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokens and Their NER Information: \n",
      "\n",
      "Token: Building, Not part of any entity.\n",
      "Token: a, Not part of any entity.\n",
      "Token: wall, Not part of any entity.\n",
      "Token: on, Not part of any entity.\n",
      "Token: the, Not part of any entity.\n",
      "Token: U.S.-Mexico, Entity Type: ORG (Companies, agencies, institutions, etc.)\n",
      "Token: border, Not part of any entity.\n",
      "Token: will, Not part of any entity.\n",
      "Token: take, Not part of any entity.\n",
      "Token: literally, Entity Type: DATE (Absolute or relative dates or periods)\n",
      "Token: years, Entity Type: DATE (Absolute or relative dates or periods)\n",
      "Token: ., Not part of any entity.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTokens and Their NER Information: \\n\")\n",
    "\n",
    "for token in doc:\n",
    "    if token.ent_type_:\n",
    "        print(f\"Token: {token.text}, Entity Type: {token.ent_type_} ({spacy.explain(token.ent_type_)})\")\n",
    "    else:\n",
    "        print(f\"Token: {token.text}, Not part of any entity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "['Building', 'a', 'wall', 'on', 'the', 'U', '.', 'S', '.-', 'Mexico', 'border', 'will', 'take', 'literally', 'years', '.']\n",
      "tensor([[[ 0.0000e+00,  1.2517e-06,  3.8594e-06,  2.4736e-06,  6.5118e-06,\n",
      "           1.7881e-06,  4.5747e-06,  3.7402e-06,  8.7619e-06,  4.3064e-06,\n",
      "           1.2890e-05,  4.6194e-06,  4.6492e-06,  1.9222e-06,  4.7684e-07,\n",
      "           5.4240e-06,  4.8280e-06,  6.5118e-06],\n",
      "         [ 0.0000e+00,  5.9605e-08,  1.9260e-06,  1.1623e-06,  2.6114e-06,\n",
      "           9.5740e-07,  2.2333e-06,  1.8384e-06,  4.2710e-06,  2.2557e-06,\n",
      "           5.8804e-06,  1.8310e-06,  1.8794e-06,  7.7300e-07, -1.0617e-07,\n",
      "           2.6375e-06,  2.9430e-06,  3.6247e-06]]])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "\n",
    "tokens_clear = [s.replace(\"Ġ\", \"\") for s in tokens]\n",
    "tokens_clear = tokens_clear[1:len(tokens_clear)-1]\n",
    "print(tokens_clear)\n",
    "\n",
    "print(exp)\n",
    "print(len(exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokens_aggregate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_list = generate_aggregate_list(doc,exp,tokens_clear,tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agregate nr: 0\n",
      "Is spacy NER: False\n",
      "spacy token: This\n",
      "Our model clean: ['This']\n",
      "Our model dirty: ['This']\n",
      "model exp [tensor(-8.6427e-07)]\n",
      "\n",
      "\n",
      "Agregate nr: 1\n",
      "Is spacy NER: False\n",
      "spacy token: would\n",
      "Our model clean: ['would']\n",
      "Our model dirty: ['Ġwould']\n",
      "model exp [tensor(-1.0673e-06)]\n",
      "\n",
      "\n",
      "Agregate nr: 2\n",
      "Is spacy NER: False\n",
      "spacy token: be\n",
      "Our model clean: ['be']\n",
      "Our model dirty: ['Ġbe']\n",
      "model exp [tensor(1.6764e-08)]\n",
      "\n",
      "\n",
      "Agregate nr: 3\n",
      "Is spacy NER: False\n",
      "spacy token: the\n",
      "Our model clean: ['the']\n",
      "Our model dirty: ['Ġthe']\n",
      "model exp [tensor(-3.7365e-06)]\n",
      "\n",
      "\n",
      "Agregate nr: 4\n",
      "Is spacy NER: False\n",
      "spacy token: largest\n",
      "Our model clean: ['largest']\n",
      "Our model dirty: ['Ġlargest']\n",
      "model exp [tensor(-1.6391e-07)]\n",
      "\n",
      "\n",
      "Agregate nr: 5\n",
      "Is spacy NER: False\n",
      "spacy token: casino\n",
      "Our model clean: ['casino']\n",
      "Our model dirty: ['Ġcasino']\n",
      "model exp [tensor(3.7067e-07)]\n",
      "\n",
      "\n",
      "Agregate nr: 6\n",
      "Is spacy NER: False\n",
      "spacy token: in\n",
      "Our model clean: ['in']\n",
      "Our model dirty: ['Ġin']\n",
      "model exp [tensor(2.2408e-06)]\n",
      "\n",
      "\n",
      "Agregate nr: 7\n",
      "Is spacy NER: True\n",
      "spacy token: the\n",
      "Our model clean: ['the']\n",
      "Our model dirty: ['Ġthe']\n",
      "model exp [tensor(1.5460e-07)]\n",
      "\n",
      "\n",
      "Agregate nr: 8\n",
      "Is spacy NER: True\n",
      "spacy token: United\n",
      "Our model clean: ['United']\n",
      "Our model dirty: ['ĠUnited']\n",
      "model exp [tensor(3.3006e-06)]\n",
      "\n",
      "\n",
      "Agregate nr: 9\n",
      "Is spacy NER: True\n",
      "spacy token: States\n",
      "Our model clean: ['States']\n",
      "Our model dirty: ['ĠStates']\n",
      "model exp [tensor(2.1979e-06)]\n",
      "\n",
      "\n",
      "Agregate nr: 10\n",
      "Is spacy NER: False\n",
      "spacy token: .\n",
      "Our model clean: ['.']\n",
      "Our model dirty: ['.']\n",
      "model exp [tensor(8.4192e-07)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for aggregate in aggregate_list:\n",
    "    print(f\"Agregate nr: {i}\")\n",
    "    print(f\"Is spacy NER: {aggregate.is_spacy_NER}\")\n",
    "    print(f\"spacy token: {aggregate.get_spacy_token()}\")\n",
    "    clean,dirty = aggregate.get_model_tokens()\n",
    "    print(f\"Our model clean: {clean}\")\n",
    "    print(f\"Our model dirty: {dirty}\")\n",
    "    print(f\"model exp {aggregate.get_model_exp()}\")\n",
    "    print(\"\\n\")\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     obs_pt \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtokenizer(obs, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m     11\u001b[0m attr \u001b[38;5;241m=\u001b[39m FeatureAblationText(forward)\n\u001b[1;32m---> 13\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mattr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attributions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobs_pt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m tokens \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(obs_pt[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     17\u001b[0m doc \u001b[38;5;241m=\u001b[39m NER(obs)\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\nlp-2024-fake\\engine\\xai.py:29\u001b[0m, in \u001b[0;36mFeatureAblationText.get_attributions\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m     27\u001b[0m exps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(obs))]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, ob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(obs):\n\u001b[1;32m---> 29\u001b[0m     exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     exps[idx] \u001b[38;5;241m=\u001b[39m exp\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(exps)\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\captum\\log\\__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\captum\\attr\\_core\\feature_ablation.py:351\u001b[0m, in \u001b[0;36mFeatureAblation.attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, feature_mask, perturbations_per_eval, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[0;32m    332\u001b[0m     current_inputs,\n\u001b[0;32m    333\u001b[0m     current_add_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;66;03m#   non-agg mode:\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;66;03m#     (feature_perturbed * batch_size, *initial_eval.shape[1:])\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     modified_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strict_run_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_add_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m show_progress:\n\u001b[0;32m    359\u001b[0m         attr_progress\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\captum\\attr\\_core\\feature_ablation.py:599\u001b[0m, in \u001b[0;36mFeatureAblation._strict_run_forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strict_run_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;124;03m    A temp wrapper for global _run_forward util to force forward output\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m    type assertion & conversion.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03m    Remove after the strict logic is supported by all attr classes\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 599\u001b[0m     forward_output \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(forward_output, Tensor):\n\u001b[0;32m    601\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m forward_output\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\captum\\_utils\\common.py:531\u001b[0m, in \u001b[0;36m_run_forward\u001b[1;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[0;32m    528\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _format_inputs(inputs)\n\u001b[0;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m--> 531\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _select_targets(output, target)\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(obs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(obs):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1318\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1318\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1330\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:976\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    974\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 976\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    989\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    622\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m         output_attentions,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:520\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:447\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    439\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    446\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 447\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    457\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\1234o\\Studies\\Sem2\\NLP\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370\u001b[0m, in \u001b[0;36mRobertaSdpaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    368\u001b[0m )\n\u001b[1;32m--> 370\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    380\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "all_aggregate = []\n",
    "i =0\n",
    "for obs in test[\"text\"].tolist():\n",
    "    print(i)\n",
    "    i=i+1\n",
    "    if(device == \"cuda\"):\n",
    "        obs_pt = pipeline.tokenizer(obs, return_tensors=\"pt\")['input_ids'].cuda()\n",
    "    else:\n",
    "        obs_pt = pipeline.tokenizer(obs, return_tensors=\"pt\")['input_ids'].cpu()\n",
    "    attr = FeatureAblationText(forward)\n",
    "\n",
    "    exp = attr.get_attributions([obs_pt])\n",
    "    tokens = pipeline.tokenizer.convert_ids_to_tokens(obs_pt[0])\n",
    "\n",
    "\n",
    "    doc = NER(obs)\n",
    "    tokens_clear = [s.replace(\"Ġ\", \"\") for s in tokens]\n",
    "    tokens_clear = tokens_clear[1:len(tokens_clear)-1]\n",
    "    spacy_token_to_our_tokens = generate_aggregate_list(doc,exp,tokens_clear,tokens)\n",
    "    all_aggregate = all_aggregate+spacy_token_to_our_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1234o\\AppData\\Local\\Temp\\ipykernel_17884\\2923972711.py:18: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(arrays, labels=labels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x21f200f18e0>,\n",
       "  <matplotlib.lines.Line2D at 0x21f200f1a90>,\n",
       "  <matplotlib.lines.Line2D at 0x21f200f2ae0>,\n",
       "  <matplotlib.lines.Line2D at 0x21f200f2de0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x21f200f1d60>,\n",
       "  <matplotlib.lines.Line2D at 0x21f200f2000>,\n",
       "  <matplotlib.lines.Line2D at 0x21f200f30e0>,\n",
       "  <matplotlib.lines.Line2D at 0x21f200f3320>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x21f200edb50>,\n",
       "  <matplotlib.lines.Line2D at 0x21f200f2840>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x21f200f22d0>,\n",
       "  <matplotlib.lines.Line2D at 0x21f200f35f0>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x21f200f25d0>,\n",
       "  <matplotlib.lines.Line2D at 0x21f200f3860>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "i = 0\n",
    "NER_values = []\n",
    "non_NER_values = []\n",
    "for aggregate in all_aggregate:\n",
    "    value = np.max(aggregate.get_model_exp())\n",
    "    if(aggregate.is_spacy_NER):\n",
    "        NER_values.append(value)\n",
    "    else:\n",
    "        non_NER_values.append(value)\n",
    "\n",
    "data_to_show = {\"NER\":NER_values,\"NOT NER\":non_NER_values}\n",
    "arrays = list(data_to_show.values())\n",
    "labels = list(data_to_show.keys())\n",
    "plt.ylabel(\"Max of token exp\")\n",
    "\n",
    "plt.boxplot(arrays, labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
